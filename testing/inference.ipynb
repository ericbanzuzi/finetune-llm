{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K7qOSuFsReS"
      },
      "source": [
        "# Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aJKD4IFWruak"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "Let's run the model! You can change the instruction and input - leave the output blank!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "3892cb2c1fdf4c20937eb4f8e0f20c52",
            "0cd9425dbdbf4d319c3a84721274826d",
            "76febaa98da14bd9a812901397966d40",
            "6d7e256fada34e118fdbe1cf35e164d1",
            "244d4cad93ce481b8f474574645bbc4d",
            "6f44ce8abe2641f7a501570acd21947b",
            "4e9eaf672a2a4029868a210a45bba26d",
            "c02e7c2260c04125a0df8477a137939b",
            "11d09907863342a5a40b97161a60fb77",
            "fa3860ebe99444e09da6f0dcb49ab831",
            "28f9dafe4fce446189409ab2a180eb26"
          ]
        },
        "id": "S0mk7cQKstq7",
        "outputId": "a1f35e73-8212-45e0-8d75-4f7e5477370e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3892cb2c1fdf4c20937eb4f8e0f20c52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None # None for auto detection.\n",
        "load_in_4bit = True\n",
        "\n",
        "fourbit_models = [\n",
        "    \"rcarioniporras/model_baseline_llama\",\n",
        "    \"ericbanzuzi/model_datacentric_llama\",\n",
        "    \"rcarioniporras/model_modelcentric_llama\",\n",
        "]\n",
        "\n",
        "hf_token = 'token'\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = fourbit_models[2],\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "f3fd7b6f-757f-47ad-efe6-3747705081c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A decorator in Python is a technique to dynamically apply some behavior or function to another function. It essentially wraps another function to execute additional code before, after, or between each execution of the main function. Decors are useful for customizing the behavior of another function based on some condition.\n",
            "\n",
            "For example, the decorator we want to use in this question is likely to log the execution time of a function. This is commonly used in Python scripts to monitor how quickly certain functions execute. By adding this decorator to a function, it can log the execution time at the beginning, middle, and end of the function's execution. It also keeps track of the number of times it executes, as well as when it started running and stopped. This can provide a great deal of valuable information for debugging purposes.\n",
            "\n",
            "Here's an example of a decorator that logs execution times using the 'time' module:\n",
            "\n",
            "```python\n",
            "import time\n",
            "\n",
            "def time_log(func):\n",
            "    def wrapper(*args, **kwargs):\n",
            "        start_time = time.perf_counter()\n",
            "        result = func(*args, **kwargs)\n",
            "        end_time = time.perf_counter()\n",
            "        elapsed_time = end_time - start_time\n",
            "        print(\"Execution time: {:.4f}s\".format(elapsed_time))\n",
            "        print(\"Function: {}\".format(func.__name__))\n",
            "        print(\"Number of times executed: {}\".format(len(func)))\n",
            "\n",
            "        return result\n",
            "    return wrapper\n",
            "\n",
            "@time_log\n",
            "def my_func():\n",
            "    print(\"This is my_func.\")\n",
            "    time.sleep(1)\n",
            "    print(\"This is another line of code.\")\n",
            "\n",
            "my_func()\n",
            "```\n",
            "\n",
            "The decorator function `time_log` defines a function `wrapper` inside of `time_log`. The `wrapper` function captures the start and end times using the `time.perf_counter()` function, and the `len(func)` function to determine the total number of times the decorator is called. It then logs these statistics along with the function call result using print statements.\n",
            "\n",
            "By applying the decorator `@time_log` to the function `my_func`, we can use the decorated function to log its execution times each time it is executed. The function call to `my_func` will also log each time, along with the function name and the total execution time.\n",
            "\n",
            "Please note that the decorator `@time_log` is added to `my_func` at the beginning. This is necessary to apply the decorator before the function actually executes.\n",
            "\n",
            "If you run the program with `my_func` as a function of the decorated `time_log` decorator, you should get output like this:\n",
            "\n",
            "```\n",
            "This is my_func.\n",
            "Execution time: 1.0022s\n",
            "This is another line of code.\n",
            "```<|eot_id|>\n",
            "To complete the function and make it complete, we need to check if the given number is prime or not. We can use the same algorithm we have been using before to find the factors of the number and check if any of them divide it evenly. If any of them divide it evenly, then it is not prime. \n",
            "\n",
            "Here's the complete code:\n",
            "\n",
            "```python\n",
            "def is_prime(num):\n",
            "    if num < 2:\n",
            "        return False\n",
            "\n",
            "    for i in range(2, int(num**0.5) + 1):\n",
            "        if num % i == 0:\n",
            "            return False\n",
            "\n",
            "    return True\n",
            "```\n",
            "\n",
            "This function will return True if the given number is prime, and False otherwise.<|eot_id|>\n",
            "In Python, the Global Interpreter Lock (GIL) is a hardware-based synchronization mechanism that prevents multiple threads from executing Python bytecode simultaneously. This GIL allows only one thread to execute at a time, which reduces the performance of CPU-bound programs, especially those relying heavily on multi-core processors.\n",
            "\n",
            "The GIL was introduced as an optimization, providing better performance by allowing a single thread to execute Python bytecodes at a faster speed than would be possible on a multi-core system. The GIL is currently around 200-300 nanoseconds long per bytecode.\n",
            "\n",
            "Multithreading in Python with the GIL involves creating multiple threads in a process, which is allowed because Python does not have a full native multithreading system. This allows you to create multiple threads for different tasks or operations without impacting the execution of other tasks.\n",
            "\n",
            "However, creating too many threads can negatively impact performance as it increases memory usage and creates unnecessary system resource management overhead.\n",
            "\n",
            "There are ways to work around the limitations imposed by the GIL in Python:\n",
            "\n",
            "1. Use multiprocessing: Python provides a higher-level module for creating processes, called the \"multiprocessing module\". This allows creating independent threads and is a more flexible solution for achieving true multi-core parallelism. However, it is platform-specific.\n",
            "\n",
            "2. Use asynchronous I/O (asyncio): The asyncio library in Python offers an efficient way to write concurrent code by leveraging the GIL in a much more effective way. It creates lightweight threads that share a single CPU core and are much more lightweight than processes, allowing for efficient utilization of all available CPU cores. It does not require explicit creation of threads but instead manages to keep the program execution rate higher than if using threads.\n",
            "\n",
            "3. Utilize the multiprocessing library, but keep in mind it is a lower-level library and its usage can be more complex.\n",
            "\n",
            "In summary, the Python GIL impacts multithreading performance due to its memory-intensive nature. However, using multiprocessing, asynchronous I/O (asyncio), or other approaches can help to work around its limitations and improve performance in multi-core systems.<|eot_id|>\n",
            "The stack data structure is a linear data structure that follows the Last-In-First-Out (LIFO) principle. It stores elements in a vertical manner, meaning the last element added or removed is the first one to appear or be removed. The main operation of a stack is \"push,\" where new elements are added to the top, and \"pop\" removes elements from the top. An example of using a stack would be in a method that handles parsing a programming language grammar rules, where a string is seen to be in a specific order and when the end of the string is reached, the parsing stops.\n",
            "\n",
            "On the other hand, the queue data structure follows the First-In-First-Out (FIFO) principle. It stores elements in a horizontal manner, meaning the first element added to the queue becomes the first element to be removed. The main operation of a queue is \"enqueue,\" where new elements are added to the end, and \"dequeue\" removes elements from the front, where the oldest element is removed first. An example use case for a queue could be in a task scheduler, where tasks are added to a queue and can be removed one by one based on their priority or time. Another use case could be in a vending machine, where the customer can insert coins into the machine and a randomly chosen product is dispensed.<|eot_id|>\n",
            "Object-oriented programming (OOP) is a programming paradigm based on the concept of \"objects.\" These objects are made up of various properties and methods that operate upon them. OOP focuses on organizing and structuring code in a logical and meaningful way.\n",
            "\n",
            "One of the primary principles of OOP is the \"encapsulation principle,\" which emphasizes the bundling of data and methods within objects, thus encapsulating and protecting their inner workings. This is achieved through the use of class definitions and the use of the \"access modifier\" to control access to the object's private and protected data.\n",
            "\n",
            "The second principle of OOP is the \"abstraction principle.\" This principle is about extracting essential functionality from objects and presenting their interfaces, known as \"interfaces.\" In OOP, an object's properties are often abstract, and its behavior is described by an interface that defines the methods that objects should implement.\n",
            "\n",
            "The third principle is the \"inheritance principle.\" This principle states that a child class inherits all the properties and methods from its parent class. The child class can then extend the properties and methods of its parent class, building upon their functionality.\n",
            "\n",
            "The fourth principle is the \"polymorphism principle.\" Polymorphism allows different objects to have the same methods. This can be achieved through the use of \"polymorphic\" functions or classes. It means that methods of one type can be accessed using a different type's method. This provides flexibility and allows for more reusable and adaptable code.<|eot_id|>\n",
            "The greenhouse effect is a natural process that helps warm the Earth's surface, which is vital for life. It occurs when gases in the atmosphere, including greenhouse gases, trap heat from the sun and radiate it back towards the Earth. This warm energy reaches our planet's surface, causing it to heat up. If the rate of the sun's energy reaches Earth's surface, we may feel a sensation of heat or it is summer time. Greenhouse gases include carbon dioxide (CO2), methane (CH4), water vapor (H2O), and nitrous oxide (N2O). While they are essential for life as greenhouse gases are released as a natural consequence of burning fossil fuels, deforestation or changing land use patterns.<|eot_id|>\n",
            "The Industrial Revolution was caused by advances in technology, such as the use of steam engines, spinning jigs, and manufacturing machinery. These changes allowed for mass production, leading to increased efficiency and lower production costs. The industrial revolution had a significant impact on the modern world by transforming the way goods were produced, making things more affordable for the general public.\n",
            "\n",
            "The industrial revolution brought significant economic growth and urbanization to many parts of the world. It led to an increase in standard of living and provided more jobs for people.\n",
            "\n",
            "However, the industrial revolution also created problems. Many people moved from rural areas to cities in search of employment, and they often faced poor living conditions. There was also the issue of poverty, as people became dependent on the goods produced by industry.\n",
            "\n",
            "Furthermore, the industrial revolution had an environmental impact. Large amounts of waste generated from the new manufacturing processes led to pollution and other issues.<|eot_id|>\n",
            "The sine of an angle, denoted by $\\sin$, is defined as the ratio of the length of the side opposite the angle in a right triangle to the length of the hypotenuse. In the context of the unit circle, the sine function relates to the coordinates of a point on the unit circle.<|eot_id|>\n",
            "The probability of an event is the number of ways that the event can occur divided by the total number of possible outcomes. In this case, the event of interest is selecting a blue ball, and the possible outcomes are selecting a red, blue, or green ball.\n",
            "\n",
            "There are a total of 3 red balls, 2 blue balls, and 5 green balls. So, there are 10 possible balls that can be selected (3 red + 2 blue + 5 green).\n",
            "\n",
            "If we select a blue ball, there is only 1 blue ball. So, the number of blue balls that can be selected is 1, and the number of possible blue balls is 1.\n",
            "\n",
            "So, the probability of selecting a blue ball is:\n",
            "\n",
            "Probability = Number of favorable outcomes / Total number of possible outcomes\n",
            "Probability = 1 blue ball / 10 balls\n",
            "Probability = 1/10\n",
            "Probability = 0.1 or 10%\n",
            "\n",
            "Therefore, the probability of selecting a blue ball is 0.1, which means there is a 10% chance of selecting a blue ball out of 100 balls.<|eot_id|>\n",
            "Simplifying algebraic expressions can often involve a series of rules and concepts. In this case, there is a use for the distributive property of multiplication over addition. \n",
            "\n",
            "The distributive property states that you can \"divide a number by a sum or difference\", by multiplying the first factor in the sum or difference by the other factors. \n",
            "\n",
            "So, first let’s look at the term 3(x+4). Here, 3 is being multiplied by the term x, which is similar to multiplying the number 1 by the sum (x+4). \n",
            "\n",
            "Using the distributive property, 3(x+4) = 3*x+3*4.\n",
            "\n",
            "Now, let’s look at 2(2x−1). Here, we're multiplying 2 by the term 2x, and also the term -1.\n",
            "\n",
            "Using the distributive property, 2(2x−1) = 2*2x -2*1.\n",
            "\n",
            "So now, putting it all together we can simplify the given expression 3(x+4)−2(2x−1). \n",
            "\n",
            "From this, we can see that we can first distribute the 3 to the x term and then to the 4 term, which leaves only the 3 term multiplied by the constant term in the second expression, i.e, -2*x -2.\n",
            "\n",
            "This can be put into a simplified form by adding the -2x term in the first expression with -2. This is because multiplying an expression by -2 is the same as dividing the first term of the expression by the second. \n",
            "\n",
            "So, now we have, -2x -2 + 3x = x -2.\n",
            "\n",
            "Therefore, the simplified expression for 3(x+4) - 2(2x−1) is x-2.<|eot_id|>\n",
            "Results have been saved to output_modelcentric.txt\n"
          ]
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "from transformers import TextStreamer\n",
        "\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "test_messages = [\n",
        "    # coding tasks\n",
        "    {\"role\": \"user\", \"content\": \"What is a decorator in Python, and why is it used? Provide an example of a decorator to log the execution time of a function.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Complete the following Python function to determine whether a given number is prime: def is_prime(num):  # Your code here\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain Python's Global Interpreter Lock (GIL). How does it affect multithreading in Python? What are some ways to work around it?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compare the stack and queue data structures. Provide an example use case for each.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is object-oriented programming (OOP), and what are its four main principles?\"},\n",
        "\n",
        "    # general tasks for following instructions\n",
        "    {\"role\": \"user\", \"content\": \"Describe the greenhouse effect and its role in global warming. Include examples of gases that contribute to this phenomenon.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain the causes and consequences of the Industrial Revolution. How did it shape the modern world?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain the sine function and its relation to the unit circle.\"},\n",
        "    {\"role\": \"user\", \"content\": \"A bag contains 3 red balls, 2 blue balls, and 5 green balls. If one ball is selected at random, what is the probability that it is blue? Explain your answer.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Simplify the expression 3(x+4)−2(2x−1). Show all steps and explain the rules of algebra used.\"}\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "output_file = \"output_modelcentric.txt\"\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    for i, message in enumerate(test_messages):\n",
        "        # Prepare messages and inputs\n",
        "        messages = [message]\n",
        "        f.write(f\"User {i}: {message['content']}\\n\\n\")\n",
        "\n",
        "        inputs = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,  # Must add for generation\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        f.write(\"Assistant:\\n\")\n",
        "        text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "        \n",
        "        outputs = model.generate(input_ids=inputs, streamer=text_streamer, max_new_tokens=max_seq_length,\n",
        "                                 use_cache=True, temperature=1.5, min_p=0.1)\n",
        "        # setting temperature and min_p to those values allows for quality boost: the combination allows the model to produce outputs that are both\n",
        "        # creative and less repetitive, and coherent and meaningful. \n",
        "        # min_p (minimum probability) is a threshold that removes tokens with a probability lower than the specified value before sampling\n",
        "        # temperature adjusts the randomness of the model's output by scaling the probabilities of the next token distribution before sampling\n",
        "\n",
        "        generated_text = tokenizer.batch_decode(outputs)[0]\n",
        "        f.write(generated_text + \"\\n\")\n",
        "\n",
        "        f.write(\"\\n\" + \"-\" * 80 + \"\\n\\n\")\n",
        "\n",
        "print(f\"Results have been saved to {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cd9425dbdbf4d319c3a84721274826d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f44ce8abe2641f7a501570acd21947b",
            "placeholder": "​",
            "style": "IPY_MODEL_4e9eaf672a2a4029868a210a45bba26d",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "11d09907863342a5a40b97161a60fb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "244d4cad93ce481b8f474574645bbc4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f9dafe4fce446189409ab2a180eb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3892cb2c1fdf4c20937eb4f8e0f20c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cd9425dbdbf4d319c3a84721274826d",
              "IPY_MODEL_76febaa98da14bd9a812901397966d40",
              "IPY_MODEL_6d7e256fada34e118fdbe1cf35e164d1"
            ],
            "layout": "IPY_MODEL_244d4cad93ce481b8f474574645bbc4d"
          }
        },
        "4e9eaf672a2a4029868a210a45bba26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d7e256fada34e118fdbe1cf35e164d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa3860ebe99444e09da6f0dcb49ab831",
            "placeholder": "​",
            "style": "IPY_MODEL_28f9dafe4fce446189409ab2a180eb26",
            "value": " 45.1M/45.1M [00:01&lt;00:00, 29.1MB/s]"
          }
        },
        "6f44ce8abe2641f7a501570acd21947b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76febaa98da14bd9a812901397966d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02e7c2260c04125a0df8477a137939b",
            "max": 45118424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11d09907863342a5a40b97161a60fb77",
            "value": 45118424
          }
        },
        "c02e7c2260c04125a0df8477a137939b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3860ebe99444e09da6f0dcb49ab831": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
